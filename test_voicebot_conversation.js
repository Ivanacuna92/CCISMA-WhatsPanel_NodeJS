require('dotenv').config();
const ariManager = require('./src/services/voicebot/ariManager');
const openaiVoice = require('./src/services/voicebot/openaiVoice');
const audioHandler = require('./src/services/voicebot/audioHandler');
const fs = require('fs').promises;
const path = require('path');

async function test() {
    try {
        console.log('ü§ñ Iniciando prueba de conversaci√≥n bidireccional con voicebot...\n');

        // Inicializar componentes
        await audioHandler.initialize();
        await ariManager.connect();

        // Escuchar llamadas contestadas
        ariManager.on('callAnswered', async (callData) => {
            console.log('üéâ ¬°Llamada contestada!');
            console.log(`   Canal: ${callData.channelId}`);
            console.log(`   Puente: ${callData.bridgeId}\n`);

            const conversationId = callData.channelId;
            let turnNumber = 0;

            try {
                // ===== TURNO 1: BOT SALUDA =====
                turnNumber++;
                const greeting = 'Hola, buenos d√≠as. Soy el asistente virtual de Navetec. Te llamo para presentarte una nave industrial que tenemos disponible en tu zona. ¬øTienes un momento para que te cuente?';

                console.log(`\nüîÑ TURNO ${turnNumber}: Bot habla`);
                console.log(`üîä Bot: "${greeting}"\n`);

                await speakToClient(callData, greeting, turnNumber);

                // Esperar 1 segundo despu√©s del playback
                await new Promise(resolve => setTimeout(resolve, 1000));

                // ===== TURNO 2: ESCUCHAR CLIENTE =====
                turnNumber++;
                console.log(`\nüîÑ TURNO ${turnNumber}: Cliente responde`);
                console.log('üé§ Esperando respuesta del cliente (m√°ximo 10 segundos)...\n');
                console.log('‚è∞ Tienes 10 segundos para responder despu√©s del beep...\n');

                const recordingName = `client_${Date.now()}`;
                const recordingPath = await ariManager.recordAudio(callData.channelId, recordingName, 10, true);

                // Verificar si hay voz
                const hasVoice = await audioHandler.hasVoiceActivity(recordingPath);

                if (!hasVoice) {
                    console.log('‚ö†Ô∏è  No se detect√≥ voz del cliente\n');

                    const noResponse = 'No escuch√© tu respuesta. Te llamar√© en otro momento. Que tengas buen d√≠a.';
                    turnNumber++;
                    await speakToClient(callData, noResponse, turnNumber);

                    await ariManager.hangup(callData.channelId);
                    return;
                }

                // Transcribir respuesta del cliente
                console.log('üìù Transcribiendo respuesta del cliente...');
                const transcription = await openaiVoice.transcribeAudio(recordingPath);
                console.log(`üë§ Cliente dijo: "${transcription.text}"\n`);

                // ===== TURNO 3: BOT RESPONDE =====
                turnNumber++;
                console.log(`\nüîÑ TURNO ${turnNumber}: Bot responde a cliente`);
                console.log('ü§ñ Generando respuesta con GPT...');

                const response = await openaiVoice.generateResponse(
                    transcription.text,
                    conversationId,
                    null,
                    {
                        naveType: 'Industrial',
                        naveLocation: 'Torre√≥n',
                        naveSize: '500',
                        navePrice: '2,500,000'
                    }
                );

                console.log(`üîä Bot: "${response.text}"\n`);
                await speakToClient(callData, response.text, turnNumber);

                // ===== TURNO 4: ESCUCHAR DE NUEVO =====
                turnNumber++;
                console.log(`\nüîÑ TURNO ${turnNumber}: Cliente responde`);
                console.log('üé§ Esperando segunda respuesta del cliente...\n');

                const recordingName2 = `client_${Date.now()}`;
                const recordingPath2 = await ariManager.recordAudio(callData.channelId, recordingName2, 10, false);

                const hasVoice2 = await audioHandler.hasVoiceActivity(recordingPath2);

                if (hasVoice2) {
                    const transcription2 = await openaiVoice.transcribeAudio(recordingPath2);
                    console.log(`üë§ Cliente dijo: "${transcription2.text}"\n`);

                    // Responder
                    turnNumber++;
                    const response2 = await openaiVoice.generateResponse(
                        transcription2.text,
                        conversationId
                    );
                    console.log(`üîä Bot: "${response2.text}"\n`);
                    await speakToClient(callData, response2.text, turnNumber);
                }

                // ===== DESPEDIDA =====
                turnNumber++;
                const goodbye = 'Perfecto. Un asesor se comunicar√° contigo pronto. Que tengas excelente d√≠a.';
                console.log(`\nüîÑ TURNO ${turnNumber}: Despedida`);
                console.log(`üîä Bot: "${goodbye}"\n`);
                await speakToClient(callData, goodbye, turnNumber);

                // Esperar y colgar
                await new Promise(resolve => setTimeout(resolve, 1000));
                await ariManager.hangup(callData.channelId);
                console.log('üì¥ Llamada finalizada');

            } catch (error) {
                console.error('‚ùå Error en la conversaci√≥n:', error);
                try {
                    await ariManager.hangup(callData.channelId);
                } catch (e) {}
            }
        });

        // Originar llamada
        const phoneNumber = process.argv[2] || '7714144641';
        console.log(`üìû Llamando a ${phoneNumber}...`);
        await ariManager.originateCall(phoneNumber);

        // Esperar 120 segundos para la conversaci√≥n
        await new Promise(resolve => setTimeout(resolve, 120000));

        console.log('\n‚úÖ Prueba completada');
        ariManager.disconnect();
        process.exit(0);

    } catch (error) {
        console.error('‚ùå Error:', error);
        process.exit(1);
    }
}

async function speakToClient(callData, text, turnNumber) {
    try {
        // Generar audio con TTS
        const audioPath = path.join('/tmp', `voicebot_turn_${turnNumber}_${Date.now()}.wav`);
        const ttsResult = await openaiVoice.textToSpeech(text, audioPath);

        // Convertir para Asterisk
        const asteriskAudioPath = await audioHandler.convertForAsteriskPlayback(ttsResult.path);

        // Copiar a directorio de Asterisk
        const asteriskSoundsPath = '/usr/share/asterisk/sounds/custom';
        await fs.mkdir(asteriskSoundsPath, { recursive: true });
        const filename = path.basename(asteriskAudioPath, '.gsm');
        const destPath = path.join(asteriskSoundsPath, `${filename}.gsm`);
        await fs.copyFile(asteriskAudioPath, destPath);

        // Reproducir en el canal del cliente
        const soundPath = `custom/${filename}`;
        await ariManager.playAudio(callData.bridgeId, soundPath, callData.channelId);

        console.log('‚úÖ Audio reproducido al cliente');

    } catch (error) {
        console.error('‚ùå Error reproduciendo audio:', error);
        throw error;
    }
}

test();
