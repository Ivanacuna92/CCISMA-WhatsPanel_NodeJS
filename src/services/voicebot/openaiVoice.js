const axios = require('axios');
const fs = require('fs').promises;
const FormData = require('form-data');
const path = require('path');
require('dotenv').config();

class OpenAIVoiceService {
    constructor() {
        this.apiKey = process.env.OPENAI_API_KEY;
        this.baseURL = 'https://api.openai.com/v1';
        this.ttsVoice = process.env.OPENAI_TTS_VOICE || 'nova';
        this.whisperLanguage = process.env.OPENAI_WHISPER_LANGUAGE || 'es';
        // Modelo r√°pido para conversaci√≥n, modelo preciso para an√°lisis
        this.gptModelFast = process.env.OPENAI_GPT_MODEL_FAST || 'gpt-4o-mini';
        this.gptModelAnalysis = process.env.OPENAI_GPT_MODEL_ANALYSIS || 'gpt-4o';
        this.conversationContexts = new Map();
    }

    // ==================== WHISPER (Speech-to-Text) ====================

    async transcribeAudio(audioFilePath, language = null) {
        try {
            const formData = new FormData();
            const audioBuffer = await fs.readFile(audioFilePath);

            formData.append('file', audioBuffer, {
                filename: path.basename(audioFilePath),
                contentType: 'audio/wav'
            });
            formData.append('model', 'whisper-1');
            formData.append('language', language || this.whisperLanguage);
            // Prompt optimizado para llamadas telef√≥nicas de ventas
            formData.append('prompt', 'Llamada telef√≥nica de ventas de naves industriales. El cliente responde con frases cortas como: s√≠, no, me interesa, est√° bien, claro, ma√±ana, el lunes, a las diez, no gracias, despu√©s.');

            const response = await axios.post(
                `${this.baseURL}/audio/transcriptions`,
                formData,
                {
                    headers: {
                        ...formData.getHeaders(),
                        'Authorization': `Bearer ${this.apiKey}`
                    },
                    timeout: 10000 // 10 segundos m√°ximo para Whisper
                }
            );

            console.log('‚úÖ Transcripci√≥n Whisper:', response.data.text);

            return {
                text: response.data.text,
                language: response.data.language,
                duration: response.data.duration
            };
        } catch (error) {
            console.error('‚ùå Error en Whisper:', error.response?.data || error.message);
            throw new Error(`Error transcribiendo audio: ${error.message}`);
        }
    }

    // ==================== GPT (Text Generation) ====================

    async generateResponse(userMessage, conversationId, systemPrompt = null, context = null) {
        try {
            // Obtener o crear contexto de conversaci√≥n
            let conversationHistory = this.conversationContexts.get(conversationId) || [];

            // Si hay contexto adicional (datos del cliente), agregarlo al system prompt
            let finalSystemPrompt = systemPrompt || await this.getDefaultSystemPrompt();

            if (context) {
                finalSystemPrompt += this.formatContextData(context);
            }

            // Construir mensajes
            const messages = [
                { role: 'system', content: finalSystemPrompt },
                ...conversationHistory,
                { role: 'user', content: userMessage }
            ];

            const response = await axios.post(
                `${this.baseURL}/chat/completions`,
                {
                    model: this.gptModelFast, // Modelo r√°pido para conversaci√≥n
                    messages: messages,
                    temperature: 0.7,
                    max_tokens: 80, // Respuestas MUY cortas para menor latencia
                    presence_penalty: 0.3 // Evita repetici√≥n = respuestas m√°s directas
                },
                {
                    headers: {
                        'Authorization': `Bearer ${this.apiKey}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: 8000 // 8 segundos m√°ximo para GPT
                }
            );

            const assistantMessage = response.data.choices[0].message.content;

            // Actualizar historial de conversaci√≥n
            conversationHistory.push({ role: 'user', content: userMessage });
            conversationHistory.push({ role: 'assistant', content: assistantMessage });

            // Limitar historial a √∫ltimos 10 mensajes
            if (conversationHistory.length > 10) {
                conversationHistory = conversationHistory.slice(-10);
            }

            this.conversationContexts.set(conversationId, conversationHistory);

            console.log('‚úÖ Respuesta GPT:', assistantMessage);

            return {
                text: assistantMessage,
                tokensUsed: response.data.usage.total_tokens
            };
        } catch (error) {
            console.error('‚ùå Error en GPT:', error.response?.data || error.message);
            throw new Error(`Error generando respuesta: ${error.message}`);
        }
    }

    formatContextData(context) {
        let contextString = '\n\n=== DATOS DE LA NAVE QUE DEBES MENCIONAR ===\n';

        if (context.clientName) {
            contextString += `Cliente: ${context.clientName}\n`;
        }
        if (context.naveType) {
            contextString += `Tipo de nave: ${context.naveType}\n`;
        }
        if (context.naveLocation) {
            contextString += `Ubicaci√≥n: ${context.naveLocation}\n`;
        }
        if (context.naveSize) {
            contextString += `Tama√±o: ${context.naveSize} metros cuadrados\n`;
        }
        if (context.navePrice) {
            contextString += `Precio de venta: ${context.navePrice} pesos mexicanos\n`;
        }
        if (context.extraInfo) {
            contextString += `Info adicional: ${context.extraInfo}\n`;
        }
        if (context.strategicAdvantages) {
            contextString += `Ventajas: ${context.strategicAdvantages}\n`;
        }

        contextString += '\n¬°¬°¬°DEBES MENCIONAR TODOS ESTOS DATOS EN TU PRIMERA RESPUESTA!!!';

        return contextString;
    }

    async getDefaultSystemPrompt() {
        // Intentar cargar desde base de datos
        try {
            const voicebotDB = require('./voicebotDatabase');
            const prompt = await voicebotDB.getConfig('system_prompt');
            if (prompt) return prompt;
        } catch (error) {
            console.log('No se pudo cargar prompt de BD, usando default');
        }

        // Prompt por defecto
        return `Eres un vendedor telef√≥nico de Navetec. Vendes naves industriales (NO rentas, solo VENTA).

EL SALUDO YA SE HIZO. El cliente ya escuch√≥: "¬øTienes un momento para que te cuente?"

AHORA TU PRIMERA RESPUESTA cuando el cliente diga "s√≠", "claro", "dime", "ok", "por favor", etc:
OBLIGATORIO decir TODA esta informaci√≥n de la nave:
1. Tipo de nave
2. Ubicaci√≥n
3. Tama√±o en metros cuadrados
4. Precio en pesos mexicanos
5. Ventajas (si hay)
Y terminar con: "¬øTe gustar√≠a agendar una visita para conocerla?"

EJEMPLO DE TU PRIMERA RESPUESTA:
"Tenemos una bodega industrial en Quer√©taro, de 500 metros cuadrados, con precio de venta de 2 millones de pesos mexicanos. Est√° cerca de la autopista. ¬øTe gustar√≠a agendar una visita para conocerla?"

DESPU√âS de dar la info, si dice que S√ç quiere visita:
‚Üí Pregunta: "¬øQu√© d√≠a y hora te quedar√≠a bien?"

Cuando te d√© d√≠a y hora:
‚Üí Confirma: "Perfecto, te agendo para el [d√≠a] a las [hora]."

REGLAS:
- NUNCA preguntes por d√≠a/hora ANTES de dar la informaci√≥n de la nave
- Di "metros cuadrados" completo
- Di "pesos mexicanos" completo
- Si dice NO: "Entendido, gracias por tu tiempo."
- S√â BREVE. M√°ximo 2 oraciones por respuesta despu√©s de dar la info inicial.
- NO repitas informaci√≥n que ya dijiste.

IMPORTANTE: Tu PRIMERA respuesta SIEMPRE debe incluir TODA la informaci√≥n de la nave.`;
    }

    // ==================== TTS (Text-to-Speech) ====================

    // Normalizar texto para que el TTS pronuncie correctamente
    normalizeTextForTTS(text) {
        let normalized = text;

        // Metros cuadrados - varias formas
        normalized = normalized.replace(/(\d+)\s*m¬≤/gi, '$1 metros cuadrados');
        normalized = normalized.replace(/(\d+)\s*m2\b/gi, '$1 metros cuadrados');
        normalized = normalized.replace(/(\d+)\s*mts¬≤/gi, '$1 metros cuadrados');
        normalized = normalized.replace(/(\d+)\s*mts2\b/gi, '$1 metros cuadrados');
        normalized = normalized.replace(/(\d+)\s*metros\s*2\b/gi, '$1 metros cuadrados');

        // Pesos mexicanos - varias formas
        normalized = normalized.replace(/\$\s*(\d[\d,\.]*)\s*(MXN|pesos)?/gi, '$1 pesos mexicanos');
        normalized = normalized.replace(/(\d[\d,\.]*)\s*MXN/gi, '$1 pesos mexicanos');
        normalized = normalized.replace(/(\d[\d,\.]*)\s*pesos\s*mx/gi, '$1 pesos mexicanos');

        // N√∫meros con comas (formato mexicano) - convertir a palabras para mejor pronunciaci√≥n
        normalized = normalized.replace(/(\d{1,3}),(\d{3}),(\d{3})/g, '$1 millones $2 mil $3');
        normalized = normalized.replace(/(\d{1,3}),(\d{3})/g, '$1 mil $2');

        // Abreviaciones comunes
        normalized = normalized.replace(/\bm¬≥\b/gi, 'metros c√∫bicos');
        normalized = normalized.replace(/\bm3\b/gi, 'metros c√∫bicos');
        normalized = normalized.replace(/\bkm\b/gi, 'kil√≥metros');
        normalized = normalized.replace(/\bha\b/gi, 'hect√°reas');
        normalized = normalized.replace(/\bUSD\b/gi, 'd√≥lares');

        console.log('üìù Texto normalizado para TTS:', normalized);
        return normalized;
    }

    async textToSpeech(text, outputPath, voice = null) {
        try {
            // Normalizar texto para mejor pronunciaci√≥n
            const normalizedText = this.normalizeTextForTTS(text);

            // tts-1: r√°pido (~200ms), tts-1-hd: mejor calidad pero ~500ms m√°s lento
            // Velocidad 0.95 es un buen balance - claro pero no lento
            const ttsModel = process.env.OPENAI_TTS_MODEL || 'tts-1';
            const ttsSpeed = parseFloat(process.env.OPENAI_TTS_SPEED || '0.95');

            console.log(`üéµ Generando TTS con modelo ${ttsModel}, voz ${voice || this.ttsVoice}, velocidad ${ttsSpeed}x`);

            const response = await axios.post(
                `${this.baseURL}/audio/speech`,
                {
                    model: ttsModel, // tts-1-hd para mejor calidad
                    input: normalizedText,
                    voice: voice || this.ttsVoice,
                    response_format: 'mp3', // MP3 alta calidad
                    speed: ttsSpeed
                },
                {
                    headers: {
                        'Authorization': `Bearer ${this.apiKey}`,
                        'Content-Type': 'application/json'
                    },
                    responseType: 'arraybuffer',
                    timeout: 10000 // 10 segundos m√°ximo para TTS
                }
            );

            // Guardar audio MP3
            const mp3Path = outputPath.endsWith('.mp3') ? outputPath : outputPath.replace('.wav', '.mp3');
            await fs.writeFile(mp3Path, response.data);

            console.log(`‚úÖ TTS generado: ${mp3Path}`);

            return {
                success: true,
                path: mp3Path,
                size: response.data.length
            };
        } catch (error) {
            console.error('‚ùå Error en TTS:', error.response?.data || error.message);
            throw new Error(`Error generando audio: ${error.message}`);
        }
    }

    // ==================== FLUJO COMPLETO ====================

    async processVoiceInput(audioInputPath, audioOutputPath, conversationId, context = null) {
        const startTime = Date.now();

        try {
            // 1. Transcribir audio del cliente (Whisper)
            console.log('üé§ Transcribiendo audio del cliente...');
            const transcription = await this.transcribeAudio(audioInputPath);

            if (!transcription.text || transcription.text.trim() === '') {
                console.log('‚ö†Ô∏è  Audio vac√≠o o inaudible');
                return {
                    success: false,
                    error: 'No se detect√≥ voz en el audio'
                };
            }

            // 2. Generar respuesta con GPT
            console.log('ü§ñ Generando respuesta con GPT...');
            const response = await this.generateResponse(
                transcription.text,
                conversationId,
                null,
                context
            );

            // 3. Convertir respuesta a audio (TTS)
            console.log('üîä Convirtiendo respuesta a audio...');
            await this.textToSpeech(response.text, audioOutputPath);

            const processingTime = Date.now() - startTime;

            return {
                success: true,
                transcription: transcription.text,
                response: response.text,
                audioPath: audioOutputPath,
                processingTime: processingTime,
                tokensUsed: response.tokensUsed
            };
        } catch (error) {
            console.error('‚ùå Error procesando voz:', error);
            return {
                success: false,
                error: error.message,
                processingTime: Date.now() - startTime
            };
        }
    }

    // ==================== AN√ÅLISIS DE INTENCI√ìN ====================

    async analyzeConversationIntent(conversationHistory) {
        try {
            const today = new Date();
            const todayStr = today.toISOString().split('T')[0];
            const dayOfWeek = today.getDay(); // 0=domingo, 1=lunes, etc.

            // Primero hacer an√°lisis con regex como respaldo
            const regexAnalysis = this.analyzeWithRegex(conversationHistory);
            console.log('üìä An√°lisis regex previo:', regexAnalysis);

            const analysisPrompt = `Analiza esta conversaci√≥n de ventas telef√≥nicas y extrae informaci√≥n sobre citas agendadas.

FECHA DE HOY: ${todayStr} (${['Domingo','Lunes','Martes','Mi√©rcoles','Jueves','Viernes','S√°bado'][dayOfWeek]})

CONVERSACI√ìN COMPLETA:
${conversationHistory.map(msg => `${msg.role === 'user' ? 'CLIENTE' : 'BOT'}: ${msg.content}`).join('\n')}

CRITERIOS PARA DETECTAR CITA AGENDADA:
- El cliente mostr√≥ inter√©s positivo ("s√≠", "me interesa", "claro", "ok", "est√° bien", "va", "dale", "perfecto", "de acuerdo")
- Se mencion√≥ un d√≠a espec√≠fico ("ma√±ana", "lunes", "martes", "el viernes", "3 de enero", etc.)
- Se mencion√≥ una hora ("10", "a las 3", "en la ma√±ana", "por la tarde", "2:30", etc.)
- El bot confirm√≥ la cita ("te agendo", "te espero", "quedamos", "confirmado", "listo")

CONVERSI√ìN DE FECHAS RELATIVAS (bas√°ndote en HOY ${todayStr}):
- "ma√±ana" = d√≠a siguiente
- "pasado ma√±ana" = +2 d√≠as
- "lunes/martes/etc" = pr√≥ximo d√≠a de esa semana
- "la pr√≥xima semana" = +7 d√≠as

CONVERSI√ìN DE HORAS:
- "ma√±ana" (como hora) = 10:00
- "medio d√≠a" = 12:00
- "tarde" = 15:00
- "noche" = 19:00
- "10 de la ma√±ana" = 10:00
- "3 de la tarde" / "3 pm" = 15:00

IMPORTANTE: Si hay CUALQUIER indicio de que se acord√≥ una cita, marca agreement=true y wantsAppointment=true.

Responde √öNICAMENTE con este JSON (sin explicaciones):
{
  "interest": true/false,
  "agreement": true/false,
  "interestLevel": "high/medium/low/none",
  "wantsAppointment": true/false,
  "appointmentDate": "YYYY-MM-DD o null",
  "appointmentTime": "HH:MM o null",
  "rawDateMentioned": "texto original de fecha mencionada o null",
  "rawTimeMentioned": "texto original de hora mencionada o null",
  "clientResponse": "positivo/negativo/indeciso/no_contesto",
  "notes": "resumen breve de lo acordado o raz√≥n de no agendar"
}`;

            const response = await axios.post(
                `${this.baseURL}/chat/completions`,
                {
                    model: this.gptModelAnalysis, // Modelo preciso para an√°lisis de citas
                    messages: [
                        { role: 'system', content: 'Eres un analizador experto de conversaciones de ventas telef√≥nicas. Tu trabajo es detectar si se agend√≥ una cita. S√© generoso en la detecci√≥n - si hay indicios de inter√©s y fechas/horas mencionadas, considera que hay cita. Responde SOLO en JSON v√°lido.' },
                        { role: 'user', content: analysisPrompt }
                    ],
                    temperature: 0.2,
                    response_format: { type: 'json_object' }
                },
                {
                    headers: {
                        'Authorization': `Bearer ${this.apiKey}`,
                        'Content-Type': 'application/json'
                    }
                }
            );

            const gptAnalysis = JSON.parse(response.data.choices[0].message.content);
            console.log('üìä An√°lisis GPT:', gptAnalysis);

            // Combinar an√°lisis: si regex detect√≥ cita pero GPT no, confiar en regex
            const finalAnalysis = this.mergeAnalysis(regexAnalysis, gptAnalysis);
            console.log('üìä An√°lisis FINAL combinado:', finalAnalysis);

            return finalAnalysis;
        } catch (error) {
            console.error('‚ùå Error analizando conversaci√≥n con GPT:', error);
            // En caso de error, usar solo an√°lisis regex
            const regexOnly = this.analyzeWithRegex(conversationHistory);
            console.log('‚ö†Ô∏è Usando solo an√°lisis regex por error GPT:', regexOnly);
            return regexOnly;
        }
    }

    // An√°lisis con expresiones regulares como respaldo
    analyzeWithRegex(conversationHistory) {
        const fullText = conversationHistory.map(m => m.content.toLowerCase()).join(' ');
        const clientMessages = conversationHistory.filter(m => m.role === 'user').map(m => m.content.toLowerCase()).join(' ');
        const botMessages = conversationHistory.filter(m => m.role === 'assistant').map(m => m.content.toLowerCase()).join(' ');

        // Detectar respuestas positivas del cliente
        const positivePatterns = /\b(s√≠|si|claro|ok|est√° bien|esta bien|me interesa|interesa|va|dale|perfecto|de acuerdo|por supuesto|adelante|bueno|sale)\b/i;
        const hasPositiveResponse = positivePatterns.test(clientMessages);

        // Detectar confirmaci√≥n del bot
        const confirmPatterns = /(te agendo|te espero|quedamos|confirmado|listo|te esperamos|nos vemos|perfecto.*entonces)/i;
        const botConfirmed = confirmPatterns.test(botMessages);

        // Detectar menciones de d√≠a
        const dayPatterns = /\b(ma√±ana|pasado ma√±ana|lunes|martes|mi√©rcoles|miercoles|jueves|viernes|s√°bado|sabado|domingo|pr√≥ximo|proximo|siguiente|(\d{1,2})\s*(de\s*)?(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre))\b/i;
        const dayMatch = fullText.match(dayPatterns);

        // Detectar menciones de hora
        const timePatterns = /\b((\d{1,2})(:(\d{2}))?\s*(am|pm|de la ma√±ana|de la tarde|de la noche|hrs|horas)?|ma√±ana|medio\s*d√≠a|mediodia|tarde|noche|en la ma√±ana|por la ma√±ana|en la tarde|por la tarde)\b/i;
        const timeMatch = fullText.match(timePatterns);

        // Detectar rechazo expl√≠cito
        const rejectPatterns = /\b(no me interesa|no gracias|no puedo|no tengo tiempo|otro momento|despu√©s|despues|no estoy interesado|no quiero|cuelgo)\b/i;
        const hasRejection = rejectPatterns.test(clientMessages);

        const result = {
            interest: hasPositiveResponse && !hasRejection,
            agreement: (hasPositiveResponse && botConfirmed) || (dayMatch && timeMatch && hasPositiveResponse),
            interestLevel: hasRejection ? 'none' : (hasPositiveResponse ? 'high' : 'low'),
            wantsAppointment: hasPositiveResponse && (dayMatch !== null || timeMatch !== null),
            appointmentDate: dayMatch ? this.parseRelativeDate(dayMatch[0]) : null,
            appointmentTime: timeMatch ? this.parseRelativeTime(timeMatch[0]) : null,
            rawDateMentioned: dayMatch ? dayMatch[0] : null,
            rawTimeMentioned: timeMatch ? timeMatch[0] : null,
            clientResponse: hasRejection ? 'negativo' : (hasPositiveResponse ? 'positivo' : 'indeciso'),
            notes: `Regex: positivo=${hasPositiveResponse}, confirmado=${botConfirmed}, d√≠a=${dayMatch?.[0]}, hora=${timeMatch?.[0]}`
        };

        return result;
    }

    // Combinar an√°lisis de regex y GPT
    mergeAnalysis(regexAnalysis, gptAnalysis) {
        // Si ambos detectan cita, usar GPT (m√°s preciso en fechas)
        // Si solo regex detecta, usar regex
        // Si solo GPT detecta, usar GPT

        const merged = { ...gptAnalysis };

        // Si regex detect√≥ cita pero GPT no, confiar en regex
        if (regexAnalysis.wantsAppointment && !gptAnalysis.wantsAppointment) {
            console.log('‚ö†Ô∏è Regex detect√≥ cita que GPT no vio, usando regex');
            merged.wantsAppointment = true;
            merged.agreement = regexAnalysis.agreement;
            merged.interest = true;
        }

        // Si regex tiene fecha/hora y GPT no, usar los de regex
        if (regexAnalysis.appointmentDate && !gptAnalysis.appointmentDate) {
            merged.appointmentDate = regexAnalysis.appointmentDate;
            merged.rawDateMentioned = regexAnalysis.rawDateMentioned;
        }
        if (regexAnalysis.appointmentTime && !gptAnalysis.appointmentTime) {
            merged.appointmentTime = regexAnalysis.appointmentTime;
            merged.rawTimeMentioned = regexAnalysis.rawTimeMentioned;
        }

        // Asegurar que si hay fecha y hora, se marque como cita
        if (merged.appointmentDate && merged.appointmentTime && merged.interest) {
            merged.wantsAppointment = true;
            merged.agreement = true;
        }

        return merged;
    }

    // Convertir fecha relativa a YYYY-MM-DD
    parseRelativeDate(dateStr) {
        const today = new Date();
        const lower = dateStr.toLowerCase();

        if (lower.includes('ma√±ana') && !lower.includes('pasado')) {
            const tomorrow = new Date(today);
            tomorrow.setDate(tomorrow.getDate() + 1);
            return tomorrow.toISOString().split('T')[0];
        }

        if (lower.includes('pasado ma√±ana')) {
            const dayAfter = new Date(today);
            dayAfter.setDate(dayAfter.getDate() + 2);
            return dayAfter.toISOString().split('T')[0];
        }

        const days = ['domingo', 'lunes', 'martes', 'mi√©rcoles', 'miercoles', 'jueves', 'viernes', 's√°bado', 'sabado'];
        for (let i = 0; i < days.length; i++) {
            if (lower.includes(days[i])) {
                const targetDay = i <= 6 ? i : i - 1; // Ajustar para miercoles/sabado sin acento
                const currentDay = today.getDay();
                let daysUntil = targetDay - currentDay;
                if (daysUntil <= 0) daysUntil += 7;
                const targetDate = new Date(today);
                targetDate.setDate(targetDate.getDate() + daysUntil);
                return targetDate.toISOString().split('T')[0];
            }
        }

        // Intentar parsear fecha espec√≠fica (ej: "3 de enero")
        const months = ['enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre'];
        const dateMatch = lower.match(/(\d{1,2})\s*(de\s*)?(\w+)/);
        if (dateMatch) {
            const day = parseInt(dateMatch[1]);
            const monthStr = dateMatch[3];
            const monthIndex = months.findIndex(m => monthStr.includes(m));
            if (monthIndex !== -1) {
                const year = monthIndex < today.getMonth() ? today.getFullYear() + 1 : today.getFullYear();
                return `${year}-${String(monthIndex + 1).padStart(2, '0')}-${String(day).padStart(2, '0')}`;
            }
        }

        return null;
    }

    // Convertir hora relativa a HH:MM
    parseRelativeTime(timeStr) {
        const lower = timeStr.toLowerCase();

        // Hora espec√≠fica
        const hourMatch = lower.match(/(\d{1,2})(:(\d{2}))?/);
        if (hourMatch) {
            let hour = parseInt(hourMatch[1]);
            const minutes = hourMatch[3] ? hourMatch[3] : '00';

            // Ajustar AM/PM
            if (lower.includes('pm') || lower.includes('tarde') || lower.includes('noche')) {
                if (hour < 12) hour += 12;
            } else if (lower.includes('am') || lower.includes('ma√±ana')) {
                if (hour === 12) hour = 0;
            } else if (hour < 8) {
                // Si es menor a 8 sin especificar, probablemente es PM
                hour += 12;
            }

            return `${String(hour).padStart(2, '0')}:${minutes}`;
        }

        // Horas gen√©ricas
        if (lower.includes('ma√±ana') && !lower.includes('pasado')) return '10:00';
        if (lower.includes('medio') && lower.includes('d√≠a')) return '12:00';
        if (lower.includes('mediodia')) return '12:00';
        if (lower.includes('tarde')) return '15:00';
        if (lower.includes('noche')) return '19:00';

        return null;
    }

    // Agregar mensaje al historial (para el saludo inicial)
    addToConversationHistory(conversationId, role, content) {
        let history = this.conversationContexts.get(conversationId) || [];
        history.push({ role, content });
        this.conversationContexts.set(conversationId, history);
        console.log(`üìù Agregado al historial [${role}]: ${content.substring(0, 50)}...`);
    }

    clearConversationContext(conversationId) {
        this.conversationContexts.delete(conversationId);
        console.log(`üóëÔ∏è  Contexto de conversaci√≥n ${conversationId} eliminado`);
    }

    getConversationContext(conversationId) {
        return this.conversationContexts.get(conversationId) || [];
    }
}

module.exports = new OpenAIVoiceService();
